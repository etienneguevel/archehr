{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9a03df-3df7-4647-b4e1-807f1adb26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d1ad7b-90e5-4ded-91a1-219a1492e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archehr import PROJECT_DIR\n",
    "from archehr.data.dataset import QADataset\n",
    "from archehr.data.utils import load_data, make_query_sentence_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8896d0f-7cf9-4b31-bdb2-a9afdb9184f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class QADatasetEmbedding(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, model, device=torch.device('cpu')):\n",
    "        super(QADatasetEmbedding, self).__init__()\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.translate_dict = {\n",
    "            u: k\n",
    "            for k, u in enumerate(set([i['label'] for i in data]))\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def emb_size(self):\n",
    "        return self[0][0].size()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        query, sentence = item['query']\n",
    "\n",
    "        # make the encoding\n",
    "        encoding = self.tokenizer(\n",
    "            query,\n",
    "            sentence,\n",
    "            padding=False,\n",
    "            truncation=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encoding.to(self.device)\n",
    "\n",
    "        # make the embedding\n",
    "        with torch.no_grad():\n",
    "            embedding = self.model(**encoding)\n",
    "        \n",
    "        return embedding.logits.squeeze(0).to(device), self.translate_dict[item['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "450a6521-ea43-45f5-8ab5-601c86cfab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(model, dataloader, device, loss, target, progress_bar=None):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation set.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to evaluate.\n",
    "        dataloader: The dataloader for the validation set.\n",
    "        device: The device to use for evaluation.\n",
    "    \n",
    "    Returns:\n",
    "        The average loss and accuracy on the validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in dataloader:\n",
    "            # Move inputs and labels to device\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            with torch.no_grad():\n",
    "                outputs = model(batch)\n",
    "\n",
    "            # Compute the loss\n",
    "            l = loss(outputs, labels)\n",
    "            val_loss += l.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Compute true positives & false positives & false negatives\n",
    "            tp += sum((labels == target) & (predicted == target)).item()\n",
    "            fp += sum((labels != target) & (predicted == target)).item()\n",
    "            fn += sum((labels == target) & (predicted != target)).item()\n",
    "\n",
    "    # Compute metrics\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = (\n",
    "        2 * (precision * recall) / (precision + recall) \n",
    "        if (precision + recall) > 0 else 0\n",
    "    )\n",
    "\n",
    "    avg_loss = val_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    if progress_bar is not None:\n",
    "        progress_bar.set_postfix(\n",
    "            loss=f\"{avg_loss:.4f}\",\n",
    "            acc=f\"{accuracy:.1%}\",\n",
    "            ppv=f\"{precision:.1%}\",\n",
    "            rec=f\"{recall:.1%}\",\n",
    "            f1=f\"{f1:.1%}\",\n",
    "        )\n",
    "\n",
    "    output_dict = {\n",
    "        'loss': avg_loss,\n",
    "        'acc': accuracy,\n",
    "        'ppv': precision,\n",
    "        'rec': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb90b6dc-06be-4d31-b89e-38fe1a32bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Optional, Callable\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        hidden_features: Optional[int] = None,\n",
    "        out_features: Optional[int] = None,\n",
    "        act_layer: Callable[..., nn.Module] = nn.GELU,\n",
    "        drop: float = 0.0,\n",
    "        bias: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features, bias=bias)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features, bias=bias)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3088605-fb6a-4803-bc9d-daeedeec2426",
   "metadata": {},
   "source": [
    "## Use nli-deberta-v3-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7f4c7ff5-bd06-448c-9f19-a44ffd0ecf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data & the model\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the data\n",
    "data_path = PROJECT_DIR / \"data\" / \"1.1\" / \"dev\"\n",
    "data = load_data(data_path)\n",
    "n_cases = len(data)\n",
    "\n",
    "# Split train / val\n",
    "data_train = data[:int(0.8 * n_cases)]\n",
    "data_val = data[int(0.8 * n_cases):]\n",
    "\n",
    "# Load the model & tokenizer\n",
    "model_name = \"cross-encoder/nli-deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Remove the last layer\n",
    "model.classifier = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d87a4a1f-3043-40df-861e-1e14308f5757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Mlp(\n",
       "  (fc1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (act): GELU(approximate='none')\n",
       "  (fc2): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")\n",
    "\n",
    "# Make the pairs\n",
    "# Make the pairs\n",
    "pairs_train = make_query_sentence_pairs(data_train)\n",
    "pairs_val = make_query_sentence_pairs(data_val)\n",
    "\n",
    "# Make embedding datasets\n",
    "emb_train = QADatasetEmbedding(pairs_train, tokenizer, model, device=device)\n",
    "emb_val = QADatasetEmbedding(pairs_val, tokenizer, model, device=device)\n",
    "\n",
    "# Make embedding dataloaders\n",
    "train_loader = DataLoader(emb_train, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(emb_val, batch_size=128,)\n",
    "\n",
    "mlp = Mlp(\n",
    "    emb_train.emb_size.numel(),\n",
    "    out_features=len(emb_train.translate_dict)\n",
    ")\n",
    "mlp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a16f8c89-33f6-4383-8d45-2be1691ca018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make optimizer and loss\n",
    "optimizer = torch.optim.AdamW(mlp.parameters())\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8785c4e9-e825-4145-a0be-8a6d5caf2ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 100/100 [27:22<00:00, 16.43s/it, acc=49.6%, f1=23.9%, loss=1.4556, ppv=25.4%, rec=22.7%]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "mlp.train()\n",
    "for epoch in (progress_bar := tqdm(range(num_epochs))):\n",
    "    for batch, labels in train_loader:\n",
    "        # Move inputs and labels to device\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = mlp(batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        l = loss(outputs, labels)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        do_eval(\n",
    "            mlp,\n",
    "            val_loader,\n",
    "            device,\n",
    "            loss,\n",
    "            target=dataset_val.translate_dict['essential'],\n",
    "            progress_bar=progress_bar,    \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc30a08-c030-4078-a4ea-7c872a685e49",
   "metadata": {},
   "source": [
    "## Use other cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b9b97e64-9527-4aab-b843-142a92cb1fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L12-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-MiniLM-L12-v2')\n",
    "\n",
    "# Remove the last layer\n",
    "model.classifier = nn.Identity()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0a4f110a-d27b-4f24-8bc0-a333b9f9cd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Mlp(\n",
       "  (fc1): Linear(in_features=384, out_features=384, bias=True)\n",
       "  (act): GELU(approximate='none')\n",
       "  (fc2): Linear(in_features=384, out_features=3, bias=True)\n",
       "  (drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")\n",
    "\n",
    "# Make the pairs\n",
    "# Make the pairs\n",
    "pairs_train = make_query_sentence_pairs(data_train)\n",
    "pairs_val = make_query_sentence_pairs(data_val)\n",
    "\n",
    "# Make embedding datasets\n",
    "emb_train = QADatasetEmbedding(pairs_train, tokenizer, model, device=device)\n",
    "emb_val = QADatasetEmbedding(pairs_val, tokenizer, model, device=device)\n",
    "\n",
    "# Make embedding dataloaders\n",
    "train_loader = DataLoader(emb_train, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(emb_val, batch_size=128,)\n",
    "\n",
    "mlp = Mlp(\n",
    "    emb_train.emb_size.numel(),\n",
    "    out_features=len(emb_train.translate_dict)\n",
    ")\n",
    "mlp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ab8a133b-e81e-4719-aa72-ce76cd639ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 100/100 [10:54<00:00,  6.54s/it, acc=10.2%, f1=0.0%, loss=1.0931, ppv=0.0%, rec=0.0%]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "mlp.train()\n",
    "for epoch in (progress_bar := tqdm(range(num_epochs))):\n",
    "    for batch, labels in train_loader:\n",
    "        # Move inputs and labels to device\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = mlp(batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        l = loss(outputs, labels)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        do_eval(\n",
    "            mlp,\n",
    "            val_loader,\n",
    "            device,\n",
    "            loss,\n",
    "            target=dataset_val.translate_dict['essential'],\n",
    "            progress_bar=progress_bar,    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2879e58-181b-4670-8f68-f93aa208c803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
